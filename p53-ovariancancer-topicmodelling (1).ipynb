{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Topic Modelling for P53 in Ovarian Cancer**\n\n\n\n\n\n\n","metadata":{"id":"YCkSAs8V07Tx"}},{"cell_type":"code","source":"!pip install bertopic","metadata":{"id":"jxfEey4ANz7v","outputId":"00b2b831-4e1c-4b1a-a822-53e71d826ec3","execution":{"iopub.status.busy":"2022-11-23T22:35:00.601914Z","iopub.execute_input":"2022-11-23T22:35:00.602287Z","iopub.status.idle":"2022-11-23T22:36:31.824246Z","shell.execute_reply.started":"2022-11-23T22:35:00.602207Z","shell.execute_reply":"2022-11-23T22:36:31.823229Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting bertopic\n  Downloading bertopic-0.12.0-py2.py3-none-any.whl (90 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 KB\u001b[0m \u001b[31m963.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.41.1 in /opt/conda/lib/python3.7/site-packages (from bertopic) (4.63.0)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.7/site-packages (from bertopic) (1.21.6)\nRequirement already satisfied: umap-learn>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from bertopic) (0.5.3)\nRequirement already satisfied: plotly>=4.7.0 in /opt/conda/lib/python3.7/site-packages (from bertopic) (5.8.0)\nCollecting hdbscan>=0.8.28\n  Downloading hdbscan-0.8.29.tar.gz (5.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2.post1 in /opt/conda/lib/python3.7/site-packages (from bertopic) (1.0.2)\nCollecting pyyaml<6.0\n  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.6/636.6 KB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.7/site-packages (from bertopic) (1.3.5)\nCollecting sentence-transformers>=0.4.1\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: cython>=0.27 in /opt/conda/lib/python3.7/site-packages (from hdbscan>=0.8.28->bertopic) (0.29.28)\nRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.7/site-packages (from hdbscan>=0.8.28->bertopic) (1.7.3)\nRequirement already satisfied: joblib>=1.0 in /opt/conda/lib/python3.7/site-packages (from hdbscan>=0.8.28->bertopic) (1.0.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1.5->bertopic) (2021.3)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly>=4.7.0->bertopic) (8.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.18.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic) (1.11.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.12.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.96)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.5.1)\nRequirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.7/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.6)\nRequirement already satisfied: numba>=0.49 in /opt/conda/lib/python3.7/site-packages (from umap-learn>=0.5.0->bertopic) (0.55.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.27.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.11.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (59.8.0)\nRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.38.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.1.5->bertopic) (1.16.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.12.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2021.11.10)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.0.53)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.7)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.7.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (8.0.4)\nBuilding wheels for collected packages: hdbscan, sentence-transformers\n  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for hdbscan: filename=hdbscan-0.8.29-cp37-cp37m-linux_x86_64.whl size=3426183 sha256=24c7a7ff74afe8b0bf794b5ccbfc3d0b06cd72245f9eb3f3d9d67b0b62332725\n  Stored in directory: /root/.cache/pip/wheels/93/78/2e/03ee191669a772e9653260aa3bd53e0b1a768751a9676e8c82\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=b3ae41681c039abeb578db000d8140054de8f92ce371d554bae212c85c74bc38\n  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\nSuccessfully built hdbscan sentence-transformers\nInstalling collected packages: pyyaml, hdbscan, sentence-transformers, bertopic\n  Attempting uninstall: pyyaml\n    Found existing installation: PyYAML 6.0\n    Uninstalling PyYAML-6.0:\n      Successfully uninstalled PyYAML-6.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cudf 21.10.1 requires cupy-cuda114, which is not installed.\ndask-cudf 21.10.1 requires dask==2021.09.1, but you have dask 2022.2.0 which is incompatible.\ndask-cudf 21.10.1 requires distributed==2021.09.1, but you have distributed 2022.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bertopic-0.12.0 hdbscan-0.8.29 pyyaml-5.4.1 sentence-transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bertopic[visualization]","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:36:31.827915Z","iopub.execute_input":"2022-11-23T22:36:31.828162Z","iopub.status.idle":"2022-11-23T22:36:41.304092Z","shell.execute_reply.started":"2022-11-23T22:36:31.828133Z","shell.execute_reply":"2022-11-23T22:36:41.303239Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: bertopic[visualization] in /opt/conda/lib/python3.7/site-packages (0.12.0)\n\u001b[33mWARNING: bertopic 0.12.0 does not provide the extra 'visualization'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: scikit-learn>=0.22.2.post1 in /opt/conda/lib/python3.7/site-packages (from bertopic[visualization]) (1.0.2)\nRequirement already satisfied: hdbscan>=0.8.28 in /opt/conda/lib/python3.7/site-packages (from bertopic[visualization]) (0.8.29)\nRequirement already satisfied: plotly>=4.7.0 in /opt/conda/lib/python3.7/site-packages (from bertopic[visualization]) (5.8.0)\nRequirement already satisfied: umap-learn>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from bertopic[visualization]) (0.5.3)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.7/site-packages (from bertopic[visualization]) (1.21.6)\nRequirement already satisfied: tqdm>=4.41.1 in /opt/conda/lib/python3.7/site-packages (from bertopic[visualization]) (4.63.0)\nRequirement already satisfied: pyyaml<6.0 in /opt/conda/lib/python3.7/site-packages (from bertopic[visualization]) (5.4.1)\nRequirement already satisfied: sentence-transformers>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from bertopic[visualization]) (2.2.2)\nRequirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.7/site-packages (from bertopic[visualization]) (1.3.5)\nRequirement already satisfied: cython>=0.27 in /opt/conda/lib/python3.7/site-packages (from hdbscan>=0.8.28->bertopic[visualization]) (0.29.28)\nRequirement already satisfied: joblib>=1.0 in /opt/conda/lib/python3.7/site-packages (from hdbscan>=0.8.28->bertopic[visualization]) (1.0.1)\nRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.7/site-packages (from hdbscan>=0.8.28->bertopic[visualization]) (1.7.3)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1.5->bertopic[visualization]) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1.5->bertopic[visualization]) (2021.3)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly>=4.7.0->bertopic[visualization]) (8.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.2.post1->bertopic[visualization]) (3.1.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (1.11.0)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (0.5.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (0.1.96)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (0.12.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (3.2.4)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic[visualization]) (4.18.0)\nRequirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.7/site-packages (from umap-learn>=0.5.0->bertopic[visualization]) (0.5.6)\nRequirement already satisfied: numba>=0.49 in /opt/conda/lib/python3.7/site-packages (from umap-learn>=0.5.0->bertopic[visualization]) (0.55.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (4.11.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.27.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (21.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (4.2.0)\nRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic[visualization]) (0.38.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic[visualization]) (59.8.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.1.5->bertopic[visualization]) (1.16.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic[visualization]) (0.12.1)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic[visualization]) (0.0.53)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2021.11.10)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic[visualization]) (9.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.0.7)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.7.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (1.26.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic[visualization]) (2.0.12)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic[visualization]) (8.0.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import re\nimport pandas as pd\nfrom bertopic import BERTopic","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:36:41.305491Z","iopub.execute_input":"2022-11-23T22:36:41.305977Z","iopub.status.idle":"2022-11-23T22:37:04.119500Z","shell.execute_reply.started":"2022-11-23T22:36:41.305940Z","shell.execute_reply":"2022-11-23T22:37:04.118631Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"doc = pd.read_csv(\"../input/p53ova/P53inovarian.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:04.121514Z","iopub.execute_input":"2022-11-23T22:37:04.121847Z","iopub.status.idle":"2022-11-23T22:37:04.179022Z","shell.execute_reply.started":"2022-11-23T22:37:04.121819Z","shell.execute_reply":"2022-11-23T22:37:04.178224Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## KEYBERT","metadata":{}},{"cell_type":"code","source":"!pip install keybert","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:04.180435Z","iopub.execute_input":"2022-11-23T22:37:04.180860Z","iopub.status.idle":"2022-11-23T22:37:15.780163Z","shell.execute_reply.started":"2022-11-23T22:37:04.180825Z","shell.execute_reply":"2022-11-23T22:37:15.779229Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting keybert\n  Downloading keybert-0.7.0.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: sentence-transformers>=0.3.8 in /opt/conda/lib/python3.7/site-packages (from keybert) (2.2.2)\nRequirement already satisfied: scikit-learn>=0.22.2 in /opt/conda/lib/python3.7/site-packages (from keybert) (1.0.2)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.7/site-packages (from keybert) (1.21.6)\nRequirement already satisfied: rich>=10.4.0 in /opt/conda/lib/python3.7/site-packages (from keybert) (12.4.1)\nRequirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from rich>=10.4.0->keybert) (0.9.1)\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich>=10.4.0->keybert) (2.11.2)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from rich>=10.4.0->keybert) (4.2.0)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.2->keybert) (1.7.3)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.2->keybert) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.2->keybert) (3.1.0)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (4.18.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (0.1.96)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (0.5.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (4.63.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (0.12.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (3.2.4)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (1.11.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (4.11.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (5.4.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.27.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (21.3)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.0.53)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.12.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (1.16.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (9.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.0.7)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.7.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (1.26.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (8.0.4)\nBuilding wheels for collected packages: keybert\n  Building wheel for keybert (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keybert: filename=keybert-0.7.0-py3-none-any.whl size=23799 sha256=0c1895b0d4179b0fbd7aadd5b925b16d3957e60291ad332c8be85a5601d9ef4a\n  Stored in directory: /root/.cache/pip/wheels/85/0d/12/77d219f3ebbb22dc22234b4d665886c0eace86a26eca0aa72b\nSuccessfully built keybert\nInstalling collected packages: keybert\nSuccessfully installed keybert-0.7.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#\"../input/p53-text/P53_Ovarian_19_06_22.txt\"","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:15.781767Z","iopub.execute_input":"2022-11-23T22:37:15.782363Z","iopub.status.idle":"2022-11-23T22:37:15.787128Z","shell.execute_reply.started":"2022-11-23T22:37:15.782323Z","shell.execute_reply":"2022-11-23T22:37:15.786426Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"with open(\"../input/p53-text/P53_Ovarian_19_06_22.txt\") as file_in:\n    lines = []\n    for line in file_in:\n        lines.append(line)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:15.788828Z","iopub.execute_input":"2022-11-23T22:37:15.789079Z","iopub.status.idle":"2022-11-23T22:37:15.829374Z","shell.execute_reply.started":"2022-11-23T22:37:15.789044Z","shell.execute_reply":"2022-11-23T22:37:15.828750Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"infile = open('../input/p53-text/P53_Ovarian_19_06_22.txt', 'r')  # Open the file for reading.\n\ndata = infile.read()  # Read the contents of the file.","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:15.830561Z","iopub.execute_input":"2022-11-23T22:37:15.830796Z","iopub.status.idle":"2022-11-23T22:37:15.842995Z","shell.execute_reply.started":"2022-11-23T22:37:15.830764Z","shell.execute_reply":"2022-11-23T22:37:15.842306Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Splitting data  into 2 text file to conserve memory space","metadata":{}},{"cell_type":"code","source":"with open(\"../input/p53-text/P53_Ovarian_19_06_22.txt\",'r') as file:\n    lines = file.readlines()\n\nwith open(\"P53_1.txt\",'w') as file:\n    for line in lines[:int(len(lines)/4)]:\n        file.write(line)\n\nwith open(\"P53_2.txt\",'w') as file:\n    for line in lines[int(len(lines)/4)]:\n        file.write(line)\n\nwith open(\"P53_3.txt\",'w') as file:\n    for line in lines[int(len(lines)/4)]:\n        file.write(line)\n\nwith open(\"P53_4.txt\",'w') as file:\n    for line in lines[:int(len(lines)/4)]:\n        file.write(line)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:15.845591Z","iopub.execute_input":"2022-11-23T22:37:15.845782Z","iopub.status.idle":"2022-11-23T22:37:15.865120Z","shell.execute_reply.started":"2022-11-23T22:37:15.845758Z","shell.execute_reply":"2022-11-23T22:37:15.864475Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#./P53_1.txt\n#./P53_2.txt","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:15.868067Z","iopub.execute_input":"2022-11-23T22:37:15.868262Z","iopub.status.idle":"2022-11-23T22:37:15.871795Z","shell.execute_reply.started":"2022-11-23T22:37:15.868232Z","shell.execute_reply":"2022-11-23T22:37:15.870981Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"infile = open('./P53_1.txt', 'r')  # Open the file for reading.\n\ndata1 = infile.read()","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:15.873389Z","iopub.execute_input":"2022-11-23T22:37:15.873983Z","iopub.status.idle":"2022-11-23T22:37:15.881059Z","shell.execute_reply.started":"2022-11-23T22:37:15.873948Z","shell.execute_reply":"2022-11-23T22:37:15.880326Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"infile = open('./P53_2.txt', 'r')  # Open the file for reading.\n\ndata2 = infile.read()","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:15.883856Z","iopub.execute_input":"2022-11-23T22:37:15.884043Z","iopub.status.idle":"2022-11-23T22:37:15.890294Z","shell.execute_reply.started":"2022-11-23T22:37:15.884020Z","shell.execute_reply":"2022-11-23T22:37:15.889601Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"infile = open('./P53_3.txt', 'r')  # Open the file for reading.\n\ndata3 = infile.read()","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:15.892602Z","iopub.execute_input":"2022-11-23T22:37:15.892801Z","iopub.status.idle":"2022-11-23T22:37:15.901108Z","shell.execute_reply.started":"2022-11-23T22:37:15.892764Z","shell.execute_reply":"2022-11-23T22:37:15.900361Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"infile = open('./P53_4.txt', 'r')  # Open the file for reading.\n\ndata4 = infile.read()","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:15.902370Z","iopub.execute_input":"2022-11-23T22:37:15.902677Z","iopub.status.idle":"2022-11-23T22:37:15.911440Z","shell.execute_reply.started":"2022-11-23T22:37:15.902643Z","shell.execute_reply":"2022-11-23T22:37:15.910742Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from keybert import KeyBERT\nkw_model = KeyBERT()\nkeywords = kw_model.extract_keywords(data)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:15.912484Z","iopub.execute_input":"2022-11-23T22:37:15.912774Z","iopub.status.idle":"2022-11-23T22:37:44.333527Z","shell.execute_reply.started":"2022-11-23T22:37:15.912740Z","shell.execute_reply":"2022-11-23T22:37:44.332510Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0123c966ad274e779033fe7e9fb29296"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"998ab9c86e374905bd687e3e49394cb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e8da24937d644ecb948962a4660ae94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a057a0a1f63749ec800419094bd900b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79a8a9acd9ee4f54ad0e27e90dda06b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bf48a4b7c344725992999c1b4fd1043"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"106fe39640be42b88c658814c2613356"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6de5ab88b6ea4c1aa92e833881e57e66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a51180ce7f340348c1119cbf954de49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b14505d16b714be6a4d521a4cff6c7b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88561ba4a2064fcab0c7d1984283c9c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d91985b4754e42138322e8d2b3dc6830"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe909c017196403ab73b1bdbea89c849"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b7e6397d1b4211a05672f490dd1257"}},"metadata":{}}]},{"cell_type":"code","source":"kw_model.extract_keywords(data, keyphrase_ngram_range=(1, 1), stop_words=None,top_n = 10)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:44.335047Z","iopub.execute_input":"2022-11-23T22:37:44.335567Z","iopub.status.idle":"2022-11-23T22:37:48.548695Z","shell.execute_reply.started":"2022-11-23T22:37:44.335528Z","shell.execute_reply":"2022-11-23T22:37:48.547967Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[('ovariancancer', 0.5212),\n ('ovarian', 0.4315),\n ('malignancy', 0.3827),\n ('malignancies', 0.3816),\n ('pelvic', 0.3767),\n ('ovary', 0.371),\n ('prognostication', 0.3626),\n ('malignance', 0.362),\n ('prognoses', 0.3523),\n ('prognosis', 0.352)]"},"metadata":{}}]},{"cell_type":"code","source":"kw_model.extract_keywords(data, keyphrase_ngram_range=(1, 2), stop_words=None, top_n = 20)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:37:48.549983Z","iopub.execute_input":"2022-11-23T22:37:48.550433Z","iopub.status.idle":"2022-11-23T22:38:09.693716Z","shell.execute_reply.started":"2022-11-23T22:37:48.550395Z","shell.execute_reply":"2022-11-23T22:38:09.692710Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[('ovarian malignancies', 0.6317),\n ('ovarian cancer', 0.6289),\n ('cancers ovarian', 0.6268),\n ('ovarian cancers', 0.6202),\n ('ovarian carcinoma', 0.5944),\n ('ovarian cancerincludes', 0.5902),\n ('ovarian carcinomas', 0.5889),\n ('malignant ovarian', 0.5836),\n ('ovarian tumors', 0.5593),\n ('against ovariancancer', 0.5482),\n ('ovarian tumor', 0.5436),\n ('gynecologic cancer', 0.542),\n ('gynecologic cancers', 0.5387),\n ('of ovariancancer', 0.5379),\n ('ovariancancer in', 0.5293),\n ('ovariancancer org', 0.5292),\n ('gynecological cancers', 0.5287),\n ('ovariancancer impaired', 0.5284),\n ('oncology gynecologic', 0.5269),\n ('gynecological cancer', 0.5266)]"},"metadata":{}}]},{"cell_type":"code","source":"#keywords = kw_model.extract_keywords(data1, highlight=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:38:09.695807Z","iopub.execute_input":"2022-11-23T22:38:09.701115Z","iopub.status.idle":"2022-11-23T22:38:09.709245Z","shell.execute_reply.started":"2022-11-23T22:38:09.700993Z","shell.execute_reply":"2022-11-23T22:38:09.708213Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#keywords = kw_model.extract_keywords(data2, highlight=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:38:09.711539Z","iopub.execute_input":"2022-11-23T22:38:09.712309Z","iopub.status.idle":"2022-11-23T22:38:09.719171Z","shell.execute_reply.started":"2022-11-23T22:38:09.712247Z","shell.execute_reply":"2022-11-23T22:38:09.718241Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"kw_model.extract_keywords(data4, keyphrase_ngram_range=(3, 3), stop_words='english',use_maxsum=True, nr_candidates=20, top_n=20)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-23T22:38:09.721068Z","iopub.execute_input":"2022-11-23T22:38:09.721700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kw_model.extract_keywords(data4, keyphrase_ngram_range=(3, 3), stop_words='english',use_mmr=True, diversity=0.7, top_n=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#kw_model.extract_keywords(data, keyphrase_ngram_range=(3, 3), stop_words='english', use_mmr=True, diversity=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install yake","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import yake\nfrom keybert import KeyBERT\n# Create candidates\nkw_extractor = yake.KeywordExtractor(top=50)\ncandidates = kw_extractor.extract_keywords(data)\ncandidates = [candidate[0] for candidate in candidates]\n\n# KeyBERT init\nkw_model = KeyBERT()\nkeywords = kw_model.extract_keywords(data, candidates)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kw_model = KeyBERT()\nseed_keywords = [\"ovariancancer\"]\nkeywords = kw_model.extract_keywords(data, use_mmr=True, diversity=0.1, seed_keywords=seed_keywords)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keybert import KeyBERT\nkw_model = KeyBERT(model=\"all-MiniLM-L6-v2\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nsentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\nkw_model = KeyBERT(model=sentence_model)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install nltk","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport pandas as pd\nfrom bertopic import BERTopic","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nregex = \"\\\\b[0-9]{15}|[0-9]{12}\\\\b\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/p53ova/P53inovarian.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.rename(columns = {'abstract':'text'}, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#datacleaning\ndf.text = df.apply(lambda row: re.sub(r\"http\\S+\", \"\", row.text).lower(), 1)\ndf.text = df.apply(lambda row: \" \".join(filter(lambda x:x[0]!=\"@\", row.text.split())), 1)\ndf.text = df.apply(lambda row: \" \".join(re.sub(\"[^a-zA-Z]+\", \" \", row.text).split()), 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#remove words and digits\n#df['text'] = df['text'].apply(lambda x: re.sub('W*dw*','',x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#remove stopwords\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nstop_words.add('subject')\nstop_words.add('http')\ndef remove_stopwords(text):\n    return \" \".join([word for word in str(text).split() if word not in stop_words])\ndf['text'] = df['text'].apply(lambda x: remove_stopwords(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titles = df.text.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create model \n \np53_model = BERTopic(verbose=True)\n \n#topics, probabilities = model.fit_transform(titles)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from bertopic import BERTopic\n#p53_model = BERTopic(nr_topics=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from bertopic import BERTopic\n#topic_model = BERTopic(min_topic_size=70, n_gram_range=(1,3), verbose=True)\n#topics,probabilties  = topic_model.fit_transform(titles)\ntopics, probabilities = p53_model.fit_transform(titles)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq = p53_model.get_topic_info()\nfreq.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#topic_nr = freq.iloc[2][\"Topic\"]\ntopic_nr = freq.iloc[2][\"Topic\"] # select a frequent topic\n#p53_model.get_topic(topic_nr)\np53_model.get_topic(topic_nr)\n#nr_candidates=20, top_n=20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#p53_model.get_topic(top_n_topics=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loaded_model = BERTopic.load(\"p53_model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p53_model.get_topic_freq().head(11)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p53_model.get_topic(-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p53_model.get_topic(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = p53_model.visualize_topics(); fig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p53_model.visualize_hierarchy(top_n_topics=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p53_model.visualize_heatmap()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p53_model.get_topic(6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p53_model.visualize_barchart()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_topics, similarity = p53_model.find_topics(\"colorectal\", top_n = 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_topics ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"most_similar = similar_topics[0]\nprint(\"Most Similar Topic Info: \\n{}\".format(p53_model.get_topic(most_similar)))\nprint(\"Similarity Score: {}\".format(similarity[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%bash\nmkdir './cancerhealth_disparities_model_dir'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import pickle\n \n# Save the trained model as a pickle string.\n#saved_model = pickle.dumps(cancerhealth_disparities_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p53_model.save(\"p53_model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model in the previously created folder with the name 'my_best_model'\n#cancerhealth_disparities_model.save(\"./model_dir/my_best_model\")\n\n# Load the serialized model\nmy_best_model = BERTopic.load(\"./p53_model.h5\")\nmy_best_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = BERTopic.load(\"p53_model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p53_model.visualize_distribution(probabilities[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install octis","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load a custom dataset","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport string\nfrom octis.preprocessing.preprocessing import Preprocessing\nos.chdir(os.path.pardir)\n\n# Initialize preprocessing\npreprocessor = Preprocessing(vocabulary=None, max_features=None,\n                             remove_punctuation=True, punctuation=string.punctuation,\n                             lemmatize=True, stopword_list='english',\n                             min_chars=1, min_words_docs=0)\n# preprocess\n#../input/p53-text\n#dataset = preprocessor.preprocess_dataset(documents_path=r'..\\corpus.txt', labels_path=r'..\\labels.txt')\ndataset = preprocessor.preprocess_dataset(documents_path = '/kaggle/input/p53-text/P53_Ovarian_19_06_22.txt')\n\n# save the preprocessed dataset\ndataset.save('hello_dataset')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from octis.dataset.dataset import Dataset\nfrom octis.models.LDA import LDA\n\n# Load a dataset\ndataset = Dataset()\ndataset.load_custom_dataset_from_folder(\"dataset_folder\")\n\nmodel = LDA(num_topics=25)  # Create model\nmodel_output = model.train_model(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install keybert","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = pd.read_csv(\"../input/p53ova/P53inovarian.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keybert import KeyBERT\nkw_model = KeyBERT()\nkeywords = kw_model.extract_keywords(doc)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"JACCARD SIMILARITY SCORE","metadata":{}},{"cell_type":"code","source":"doc = \"\"\"\n         Supervised learning is the machine learning task of learning a function that\n         maps an input to an output based on example input-output pairs.[1] It infers a\n         function from labeled training data consisting of a set of training examples.[2]\n         In supervised learning, each example is a pair consisting of an input object\n         (typically a vector) and a desired output value (also called the supervisory signal).\n         A supervised learning algorithm analyzes the training data and produces an inferred function,\n         which can be used for mapping new examples. An optimal scenario will allow for the\n         algorithm to correctly determine the class labels for unseen instances. This requires\n         the learning algorithm to generalize from the training data to unseen situations in a\n         'reasonable' way (see inductive bias).\n      \"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"docu_1 = \"Ovarian cancer,Ovarian Malignancy Malignancies Pelvic Ovary Prognostication Malignance Prognoses Prognosis\"\ndocu_2 = \"Cancer Cell expression Tumor Protein Study Patient Induce Apoptosis Genes Use\"\ndocu_3= \"Cancer Mutant Tumor Mutations Type Cell Tp Protein Mdm Function\"\ndocu_4= \"Cell Cancer Expression Induce Apoptosis Study Line Level Increase Inhibit\"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard_similarity(doc1, doc2):\n \n # list unique words in the document\n words_doc1 = set(doc1.lower().split())\n words_doc2 = set(doc2.lower().split())\n \n # find the intersection of words list of doc1 & doc2\n intersection = words_doc1.intersection(words_doc2)\n \n # find the union of words list of doc1 & doc2\n union = words_doc1.union(words_doc2)\n \n # Calculate Jaccard similarity score\n # using the length of intersection set divided by the length of union set\n return float(len(intersection)) / len(union)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard_similarity(doc1, doc2, doc3, doc4):\n \n # list unique words in the document\n words_doc1 = set(doc1.lower().split())\n words_doc2 = set(doc2.lower().split())\n words_doc3 = set(doc3.lower().split()) \n words_doc4 = set(doc4.lower().split())\n \n # find the intersection of words list of doc1 & doc2\n intersection = words_doc1.intersection(words_doc2).intersection(words_doc3).intersection(words_doc4)\n \n # find the union of words list of doc1 & doc2\n union = words_doc1.union(words_doc2).union(words_doc3).union(words_doc4)\n \n # Calculate Jaccard similarity score\n # using the length of intersection set divided by the length of union set\n return float(len(intersection)) / len(union)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard_similarity(doc1, doc2, doc3):\n \n # list unique words in the document\n words_doc1 = set(doc1.lower().split())\n words_doc2 = set(doc2.lower().split())\n words_doc3 = set(doc3.lower().split())   \n \n # find the intersection of words list of doc1 & doc2\n intersection = words_doc1.intersection(words_doc2).intersection(words_doc3)\n \n # find the union of words list of doc1 & doc2\n union = words_doc1.union(words_doc2).union(words_doc3)\n \n # Calculate Jaccard similarity score\n # using the length of intersection set divided by the length of union set\n return float(len(intersection)) / len(union)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jaccard_similarity(docu_1, docu_2, docu_3,docu_4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jaccard_similarity(docu_2, docu_3,docu_4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jaccard_similarity(docu_3, docu_4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}